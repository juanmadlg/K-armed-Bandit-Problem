# K-armed-Bandit-Problem

"The multi-armed bandit problem (sometimes called the K-armed or N-armed bandit problem) is a problem in which a fixed limited set of resources must be allocated between competing (alternative) choices in a way that maximizes their expected gain, when each choice's properties are only partially known at the time of allocation, and may become better understood as time passes or by allocating resources to the choice. This is a classic reinforcement learning problem that exemplifies the explorationâ€“exploitation tradeoff dilemma."


Different implementations of the K-Armed Bandit Problem in Google Collab Notebooks:
* K-Armed Testbed (also in [GIST](https://gist.github.com/juanmadlg/bc25bc44af651d2dde48b708c2af87d9))
* K-Armed Testbed with Optimistic Initial Values (also in [GIST](https://gist.github.com/juanmadlg/1aedc22ca5fead9deae902509fe417bd))
* K-Armed Testbed with Upper-Confidence Bound (UCB) Action Selection (also in [GIST](https://gist.github.com/juanmadlg/3b038787de96454b175f25087292a0da))
